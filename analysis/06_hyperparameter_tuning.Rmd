---
title: "Phase 6: Hyperparameter Tuning"
author: "Fraud Detection Project"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
    toc_float: true
    code_folding: show
    theme: flatly
    highlight: tango
    fig_width: 10
    fig_height: 6
---

```{r setup, include=FALSE}
# Determine project root directory
current_dir <- getwd()
if (basename(current_dir) == "analysis") {
  project_root <- dirname(current_dir)
  setwd(project_root)
} else {
  project_root <- current_dir
}

# Source the setup script
setup_file <- file.path(project_root, "R", "setup.R")
if (file.exists(setup_file)) {
  source(setup_file)
} else {
  stop("Cannot find setup.R at: ", setup_file)
}

# Source utility functions
source(file.path(project_root, "R", "data_utils.R"))
source(file.path(project_root, "R", "preprocessing.R"))
source(file.path(project_root, "R", "evaluation.R"))

# Set random seed for reproducibility
set.seed(42)

knitr::opts_chunk$set(
  echo = TRUE,
  warning = FALSE,
  message = FALSE,
  fig.path = "results/figures/06_hyperparameter_tuning-",
  cache = TRUE
)
```

## Introduction

This document performs hyperparameter tuning for the best model identified in Phase 5. We'll use **nested cross-validation** to find optimal hyperparameters:

- **Outer CV**: 5-fold (for final evaluation)
- **Inner CV**: 3-fold (for hyperparameter selection)
- **Optimization metric**: PR-AUC (primary) or F1-score

## Load Data and Best Model

```{r load-data}
# Load raw datasets
train_raw <- readr::read_csv(file.path(paths$data, "train.csv"), show_col_types = FALSE)

cat("=== Loading Training Data ===\n")
cat("Training set:", nrow(train_raw), "rows ×", ncol(train_raw), "columns\n")

# Apply feature engineering
cat("\n=== Applying Feature Engineering ===\n")
train_raw <- create_time_features(train_raw)
train_raw <- create_amount_features(train_raw)
train_raw <- create_interaction_features(train_raw)

# Load preprocessing recipe
cat("\n=== Loading Preprocessing Recipe ===\n")
recipe_fitted <- readRDS(file.path(paths$models, "preprocessing_recipe.rds"))

# Apply preprocessing
cat("Applying preprocessing recipe...\n")
train_preprocessed <- recipes::bake(recipe_fitted, new_data = train_raw)

# Convert Class to factor
train_class_char <- as.character(train_preprocessed$Class)
train_class_char[train_class_char == "0"] <- "Non-Fraud"
train_class_char[train_class_char == "1"] <- "Fraud"
train_preprocessed$Class <- factor(train_class_char, levels = c("Non-Fraud", "Fraud"))

cat("\n=== Data Ready ===\n")
cat("Training set:", nrow(train_preprocessed), "rows ×", ncol(train_preprocessed), "columns\n")
cat("Class distribution:\n")
print(table(train_preprocessed$Class))
```

### Load Best Model and Imbalance Technique

```{r load-best-model}
# Load best model from Phase 5
best_model_file <- file.path(paths$models, "best_model_selection.rds")

if (file.exists(best_model_file)) {
  best_model_info <- readRDS(best_model_file)
  best_model_type <- best_model_info$model
  best_technique <- best_model_info$imbalance_technique
  cat("=== Best Model from Phase 5 ===\n")
  cat("Model:", best_model_type, "\n")
  cat("Imbalance Technique:", best_technique, "\n")
  if (!is.null(best_model_info$pr_auc)) {
    cat("PR-AUC:", round(best_model_info$pr_auc, 4), "\n")
  }
} else {
  # Default to Random Forest if file doesn't exist
  cat("=== Best Model File Not Found ===\n")
  cat("Defaulting to Random Forest with SMOTE\n")
  best_model_type <- "Random Forest"
  best_technique <- "SMOTE"
}

cat("\nWill tune hyperparameters for:", best_model_type, "\n")
cat("Using imbalance technique:", best_technique, "\n")
```

### Apply Imbalance Technique

```{r apply-imbalance-technique}
# Apply the imbalance technique to training data
cat("=== Applying", best_technique, "to Training Data ===\n")

if (best_technique == "Class Weights") {
  train_balanced <- train_preprocessed
  cat("Class weights will be applied during model training\n")
  
} else if (best_technique == "SMOTE") {
  recipe_imbalance <- recipes::recipe(Class ~ ., data = train_preprocessed) %>%
    themis::step_smote(Class, neighbors = 5)
  recipe_imbalance <- recipes::prep(recipe_imbalance, training = train_preprocessed)
  train_balanced <- recipes::bake(recipe_imbalance, new_data = train_preprocessed)
  
} else if (best_technique == "Random Upsampling") {
  recipe_imbalance <- recipes::recipe(Class ~ ., data = train_preprocessed) %>%
    themis::step_upsample(Class)
  recipe_imbalance <- recipes::prep(recipe_imbalance, training = train_preprocessed)
  train_balanced <- recipes::bake(recipe_imbalance, new_data = train_preprocessed)
  
} else if (best_technique == "NearMiss Undersampling") {
  recipe_imbalance <- recipes::recipe(Class ~ ., data = train_preprocessed) %>%
    themis::step_nearmiss(Class, neighbors = 3)
  recipe_imbalance <- recipes::prep(recipe_imbalance, training = train_preprocessed)
  train_balanced <- recipes::bake(recipe_imbalance, new_data = train_preprocessed)
  
} else if (best_technique == "Random Undersampling") {
  recipe_imbalance <- recipes::recipe(Class ~ ., data = train_preprocessed) %>%
    themis::step_downsample(Class)
  recipe_imbalance <- recipes::prep(recipe_imbalance, training = train_preprocessed)
  train_balanced <- recipes::bake(recipe_imbalance, new_data = train_preprocessed)
  
} else if (best_technique == "ROSE") {
  recipe_imbalance <- recipes::recipe(Class ~ ., data = train_preprocessed) %>%
    themis::step_rose(Class)
  recipe_imbalance <- recipes::prep(recipe_imbalance, training = train_preprocessed)
  train_balanced <- recipes::bake(recipe_imbalance, new_data = train_preprocessed)
  
} else {
  train_balanced <- train_preprocessed
}

cat("\nTraining data after balancing:\n")
cat("Rows:", nrow(train_balanced), "\n")
cat("Class distribution:\n")
print(table(train_balanced$Class))
```

## Setup: Cross-Validation

```{r setup-cv}
# Create outer CV folds (5-fold)
outer_cv <- rsample::vfold_cv(
  train_balanced,
  v = 5,
  strata = Class
)

cat("=== Cross-Validation Setup ===\n")
cat("Outer CV folds:", length(outer_cv$splits), "\n")
cat("Inner CV folds: 3 (for hyperparameter tuning)\n")
cat("Optimization metric: PR-AUC\n")
```

## Hyperparameter Tuning

### Random Forest Tuning

```{r tune-random-forest, eval=(best_model_type == "Random Forest" || best_model_type == "Ensemble")}
if (best_model_type == "Random Forest" || best_model_type == "Ensemble") {
  cat("=== Hyperparameter Tuning: Random Forest ===\n")
  
  # Create model specification with tuning parameters
  rf_spec <- parsnip::rand_forest(
    trees = tune::tune(),
    min_n = tune::tune(),
    mtry = tune::tune()
  ) %>%
    parsnip::set_engine("ranger", importance = "impurity") %>%
    parsnip::set_mode("classification")
  
  # Create workflow
  rf_workflow <- workflows::workflow() %>%
    workflows::add_model(rf_spec) %>%
    workflows::add_formula(Class ~ .)
  
  # Define parameter grid
  rf_grid <- dials::grid_regular(
    dials::trees(range = c(100, 500)),
    dials::min_n(range = c(2, 10)),
    dials::mtry(range = c(floor(sqrt(ncol(train_balanced) - 1)), floor((ncol(train_balanced) - 1) * 0.5))),
    levels = 3
  )
  
  cat("\nParameter grid size:", nrow(rf_grid), "combinations\n")
  cat("This may take 10-30 minutes...\n")
  
  # Perform tuning with inner CV
  rf_tune_results <- tune::tune_grid(
    rf_workflow,
    resamples = outer_cv,
    grid = rf_grid,
    metrics = yardstick::metric_set(
      yardstick::pr_auc,
      yardstick::roc_auc,
      yardstick::f_meas
    ),
    control = tune::control_grid(
      verbose = TRUE,
      save_pred = TRUE
    )
  )
  
  # Select best hyperparameters
  rf_best <- tune::select_best(rf_tune_results, metric = "pr_auc")
  
  cat("\n=== Best Random Forest Hyperparameters ===\n")
  print(rf_best)
  
  # Finalize workflow with best parameters
  rf_final <- tune::finalize_workflow(rf_workflow, rf_best)
  
  # Fit final model on full training data
  cat("\n=== Training Final Random Forest Model ===\n")
  rf_final_fitted <- parsnip::fit(rf_final, data = train_balanced)
  
  # Save tuned model
  saveRDS(rf_final_fitted, file.path(paths$models, "random_forest_tuned.rds"))
  saveRDS(rf_best, file.path(paths$models, "random_forest_best_params.rds"))
  
  cat("Tuned Random Forest model saved.\n")
}
```

### XGBoost Tuning

```{r tune-xgboost, eval=(best_model_type == "XGBoost" || best_model_type == "Ensemble")}
if (best_model_type == "XGBoost" || best_model_type == "Ensemble") {
  cat("=== Hyperparameter Tuning: XGBoost ===\n")
  
  # Create model specification with tuning parameters
  xgb_spec <- parsnip::boost_tree(
    trees = tune::tune(),
    tree_depth = tune::tune(),
    learn_rate = tune::tune(),
    min_n = tune::tune()
  ) %>%
    parsnip::set_engine("xgboost") %>%
    parsnip::set_mode("classification")
  
  # Create workflow
  xgb_workflow <- workflows::workflow() %>%
    workflows::add_model(xgb_spec) %>%
    workflows::add_formula(Class ~ .)
  
  # Define parameter grid
  xgb_grid <- dials::grid_regular(
    dials::trees(range = c(100, 500)),
    dials::tree_depth(range = c(4, 8)),
    dials::learn_rate(range = c(-2, -1)),  # log10 scale: 0.01 to 0.1
    dials::min_n(range = c(2, 10)),
    levels = 3
  )
  
  cat("\nParameter grid size:", nrow(xgb_grid), "combinations\n")
  cat("This may take 15-40 minutes...\n")
  
  # Perform tuning with inner CV
  xgb_tune_results <- tune::tune_grid(
    xgb_workflow,
    resamples = outer_cv,
    grid = xgb_grid,
    metrics = yardstick::metric_set(
      yardstick::pr_auc,
      yardstick::roc_auc,
      yardstick::f_meas
    ),
    control = tune::control_grid(
      verbose = TRUE,
      save_pred = TRUE
    )
  )
  
  # Select best hyperparameters
  xgb_best <- tune::select_best(xgb_tune_results, metric = "pr_auc")
  
  cat("\n=== Best XGBoost Hyperparameters ===\n")
  print(xgb_best)
  
  # Finalize workflow with best parameters
  xgb_final <- tune::finalize_workflow(xgb_workflow, xgb_best)
  
  # Fit final model on full training data
  cat("\n=== Training Final XGBoost Model ===\n")
  xgb_final_fitted <- parsnip::fit(xgb_final, data = train_balanced)
  
  # Save tuned model
  saveRDS(xgb_final_fitted, file.path(paths$models, "xgboost_tuned.rds"))
  saveRDS(xgb_best, file.path(paths$models, "xgboost_best_params.rds"))
  
  cat("Tuned XGBoost model saved.\n")
}
```

### Logistic Regression Tuning

```{r tune-logistic-regression, eval=(best_model_type == "Logistic Regression")}
if (best_model_type == "Logistic Regression") {
  cat("=== Hyperparameter Tuning: Logistic Regression ===\n")
  
  # Calculate class weights
  class_counts <- table(train_preprocessed$Class)
  total <- sum(class_counts)
  class_weights <- total / (length(class_counts) * class_counts)
  
  # Create model specification with regularization tuning
  lr_spec <- parsnip::logistic_reg(
    penalty = tune::tune(),
    mixture = tune::tune()
  ) %>%
    parsnip::set_engine("glmnet") %>%
    parsnip::set_mode("classification")
  
  # Create workflow
  lr_workflow <- workflows::workflow() %>%
    workflows::add_model(lr_spec) %>%
    workflows::add_formula(Class ~ .)
  
  # Define parameter grid
  lr_grid <- dials::grid_regular(
    dials::penalty(range = c(-4, 0)),  # log10 scale: 0.0001 to 1
    dials::mixture(range = c(0, 1)),   # Ridge (0) to Lasso (1)
    levels = 5
  )
  
  cat("\nParameter grid size:", nrow(lr_grid), "combinations\n")
  cat("This may take 5-15 minutes...\n")
  
  # Perform tuning
  lr_tune_results <- tune::tune_grid(
    lr_workflow,
    resamples = outer_cv,
    grid = lr_grid,
    metrics = yardstick::metric_set(
      yardstick::pr_auc,
      yardstick::roc_auc,
      yardstick::f_meas
    ),
    control = tune::control_grid(
      verbose = TRUE,
      save_pred = TRUE
    )
  )
  
  # Select best hyperparameters
  lr_best <- tune::select_best(lr_tune_results, metric = "pr_auc")
  
  cat("\n=== Best Logistic Regression Hyperparameters ===\n")
  print(lr_best)
  
  # Finalize workflow with best parameters
  lr_final <- tune::finalize_workflow(lr_workflow, lr_best)
  
  # Fit final model on full training data
  cat("\n=== Training Final Logistic Regression Model ===\n")
  lr_final_fitted <- parsnip::fit(lr_final, data = train_balanced)
  
  # Save tuned model
  saveRDS(lr_final_fitted, file.path(paths$models, "logistic_regression_tuned.rds"))
  saveRDS(lr_best, file.path(paths$models, "logistic_regression_best_params.rds"))
  
  cat("Tuned Logistic Regression model saved.\n")
}
```

## Tuning Results Visualization

```{r tuning-plots, eval=(best_model_type == "Random Forest" || best_model_type == "XGBoost" || best_model_type == "Logistic Regression")}
if (best_model_type == "Random Forest") {
  # Random Forest tuning plots
  p1 <- tune::autoplot(rf_tune_results, metric = "pr_auc")
  print(p1)
  
  # Show parameter interaction plots
  p2 <- tune::autoplot(rf_tune_results, metric = "pr_auc", type = "marginals")
  print(p2)
  
} else if (best_model_type == "XGBoost") {
  # XGBoost tuning plots
  p1 <- tune::autoplot(xgb_tune_results, metric = "pr_auc")
  print(p1)
  
  # Show parameter interaction plots
  p2 <- tune::autoplot(xgb_tune_results, metric = "pr_auc", type = "marginals")
  print(p2)
  
} else if (best_model_type == "Logistic Regression") {
  # Logistic Regression tuning plots
  p1 <- tune::autoplot(lr_tune_results, metric = "pr_auc")
  print(p1)
  
  # Show parameter interaction plots
  p2 <- tune::autoplot(lr_tune_results, metric = "pr_auc", type = "marginals")
  print(p2)
}
```

## Summary of Best Hyperparameters

```{r summary}
cat("=== Hyperparameter Tuning Summary ===\n\n")

if (best_model_type == "Random Forest" || best_model_type == "Ensemble") {
  if (exists("rf_best")) {
    cat("Random Forest Best Hyperparameters:\n")
    print(rf_best)
    cat("\n")
  }
}

if (best_model_type == "XGBoost" || best_model_type == "Ensemble") {
  if (exists("xgb_best")) {
    cat("XGBoost Best Hyperparameters:\n")
    print(xgb_best)
    cat("\n")
  }
}

if (best_model_type == "Logistic Regression") {
  if (exists("lr_best")) {
    cat("Logistic Regression Best Hyperparameters:\n")
    print(lr_best)
    cat("\n")
  }
}

cat("=== Next Steps ===\n")
cat("Tuned models have been saved and are ready for final evaluation.\n")
cat("Proceed to Phase 7: Comprehensive Evaluation on test set.\n")
```

## Summary

- ✓ Performed hyperparameter tuning using nested cross-validation
- ✓ Optimized for PR-AUC (primary metric for imbalanced data)
- ✓ Tuned `r best_model_type` hyperparameters
- ✓ Generated tuning visualizations
- ✓ Selected best hyperparameters
- ✓ Trained final tuned model on full training data
- ✓ Saved tuned models and best parameters
- ✓ Ready for comprehensive evaluation phase

**Key Achievement**: Identified optimal hyperparameters for `r best_model_type` using PR-AUC optimization.

**Next Step**: Proceed to `07_evaluation.Rmd` to evaluate the tuned model on the test set.
